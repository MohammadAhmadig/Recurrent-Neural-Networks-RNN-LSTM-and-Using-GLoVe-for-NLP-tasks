{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNRyXEEGynmJ3WQEltEyju+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["- Text Data: \n","One-hot encodding, Tokenize, word index, text to numeric"],"metadata":{"id":"SMBlSo7H5Fvw"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f-GFpOdq4nYh","executionInfo":{"status":"ok","timestamp":1675539577717,"user_tz":-210,"elapsed":7,"user":{"displayName":"Mo A","userId":"00449421205978629245"}},"outputId":"f63cca00-96d3-498e-ad4e-60bd87d30332"},"outputs":[{"output_type":"stream","name":"stdout","text":["sequences: [[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]\n","one_hot_results: [0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0.]\n","word_index: {'the': 1, 'cat': 2, 'sat': 3, 'on': 4, 'mat': 5, 'dog': 6, 'ate': 7, 'my': 8, 'homework': 9}\n","Found 9 unique tokens.\n"]}],"source":["from keras.preprocessing.text import Tokenizer\n","samples = ['The cat sat on the mat.', 'The dog ate my homework. ']\n","\n","tokenizer = Tokenizer(num_words=100)\n","tokenizer.fit_on_texts(samples)\n","\n","sequences = tokenizer.texts_to_sequences(samples)\n","\n","one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary' )\n","word_index = tokenizer.word_index\n","\n","print('sequences:' , sequences)\n","print('one_hot_results:' , one_hot_results[0])\n","print('word_index:' , word_index)\n","print('Found %s unique tokens.' % len(word_index) )\n","\n"]},{"cell_type":"markdown","source":["- Word Embedding with IMDB movie review data"],"metadata":{"id":"C3Qrqxi3ml17"}},{"cell_type":"code","source":["from keras.datasets import imdb\n","from keras.utils import pad_sequences\n","max_features = 10000\n","maxlen = 20\n","\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","\n","x_train = pad_sequences(x_train, maxlen=maxlen)\n","x_test = pad_sequences(x_test, maxlen=maxlen)\n"],"metadata":{"id":"y_AqId1N5EPC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Flatten, Dense, Embedding\n","\n","model = Sequential()\n","model.add(Embedding(10000, 8, input_length=maxlen) )\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n","model.summary()\n","\n","history = model.fit(x_train, y_train,\n","epochs=10,\n","batch_size=32,\n","validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FVe-8Wdm6BH6","executionInfo":{"status":"ok","timestamp":1675551836431,"user_tz":-210,"elapsed":22188,"user":{"displayName":"Mo A","userId":"00449421205978629245"}},"outputId":"aa3bcd05-14f0-452e-ada0-54f7a7a13076"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 20, 8)             80000     \n","                                                                 \n"," flatten (Flatten)           (None, 160)               0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 161       \n","                                                                 \n","=================================================================\n","Total params: 80,161\n","Trainable params: 80,161\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 2s 2ms/step - loss: 0.6635 - acc: 0.6289 - val_loss: 0.6049 - val_acc: 0.7016\n","Epoch 2/10\n","625/625 [==============================] - 1s 2ms/step - loss: 0.5297 - acc: 0.7575 - val_loss: 0.5174 - val_acc: 0.7356\n","Epoch 3/10\n","625/625 [==============================] - 1s 2ms/step - loss: 0.4553 - acc: 0.7904 - val_loss: 0.4978 - val_acc: 0.7462\n","Epoch 4/10\n","625/625 [==============================] - 1s 2ms/step - loss: 0.4197 - acc: 0.8096 - val_loss: 0.4936 - val_acc: 0.7560\n","Epoch 5/10\n","625/625 [==============================] - 1s 2ms/step - loss: 0.3944 - acc: 0.8219 - val_loss: 0.4945 - val_acc: 0.7574\n","Epoch 6/10\n","625/625 [==============================] - 1s 2ms/step - loss: 0.3749 - acc: 0.8329 - val_loss: 0.4998 - val_acc: 0.7602\n","Epoch 7/10\n","625/625 [==============================] - 1s 2ms/step - loss: 0.3571 - acc: 0.8443 - val_loss: 0.5067 - val_acc: 0.7554\n","Epoch 8/10\n","625/625 [==============================] - 1s 2ms/step - loss: 0.3403 - acc: 0.8529 - val_loss: 0.5107 - val_acc: 0.7544\n","Epoch 9/10\n","625/625 [==============================] - 1s 2ms/step - loss: 0.3236 - acc: 0.8629 - val_loss: 0.5168 - val_acc: 0.7558\n","Epoch 10/10\n","625/625 [==============================] - 1s 2ms/step - loss: 0.3066 - acc: 0.8734 - val_loss: 0.5244 - val_acc: 0.7554\n"]}]},{"cell_type":"markdown","source":["-----------------------------------------------\n","- For Better Performance we can use pre-trained word embeddings\n","\n","- Download, Extract and load IMDB data from scratch"],"metadata":{"id":"PvZQTbjwsiDY"}},{"cell_type":"code","source":["!wget http://mng.bz/0tIo #download the data file\n","\n","!unzip 0tIo # extract the file"],"metadata":{"id":"tlsydd8C1JZU","executionInfo":{"status":"ok","timestamp":1675698166560,"user_tz":-210,"elapsed":16,"user":{"displayName":"Mo A","userId":"00449421205978629245"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["-----------------------------------------\n","- Load and save data in texts and labels variables"],"metadata":{"id":"Io7P4wMo5a2y"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","#imdb_dir = '/Users/fchollet/Downloads/aclImdb' # http://mng.bz/0tIo\n","train_dir = os.path.join('aclImdb/', 'train')\n","labels = []\n","texts = []\n","\n","for label_type in ['neg', 'pos']:\n","  dir_name = os.path.join(train_dir, label_type)\n","  for fname in os.listdir(dir_name):\n","    if fname[-4:] == '.txt':\n","      f = open(os.path.join(dir_name, fname) )\n","      texts.append(f.read())\n","      f.close()\n","      if label_type == 'neg':\n","        labels.append (0)\n","      else:\n","        labels.append(1)"],"metadata":{"id":"UkONzYSY42BT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["-----------------------------\n","- Tokenize and Vectorize data"],"metadata":{"id":"vt_DNntj5x4h"}},{"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","from keras.utils import pad_sequences\n","import numpy as np\n","\n","maxlen = 100\n","training_samples = 200\n","validation_samples = 10000\n","max_words = 10000\n","\n","tokenizer = Tokenizer(num_words=max_words)\n","tokenizer.fit_on_texts(texts)\n","sequences = tokenizer.texts_to_sequences(texts)\n","\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index) )\n","\n","data = pad_sequences(sequences, maxlen=maxlen)\n","labels = np.asarray(labels)\n","print('Shape of data tensor:', data.shape)\n","print('Shape of label tensor:', labels.shape)\n","\n","indices = np.arange(data.shape[0])\n","np.random.shuffle(indices)\n","data = data[indices]\n","labels = labels[indices]\n","\n","\n","x_train = data[:training_samples]\n","y_train = labels[:training_samples]\n","X_val = data[training_samples: training_samples + validation_samples]\n","y_val = labels[training_samples: training_samples + validation_samples]"],"metadata":{"id":"V4WT6pUhqbla","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675641407962,"user_tz":-210,"elapsed":12097,"user":{"displayName":"Mo A","userId":"00449421205978629245"}},"outputId":"077d27a0-e173-4905-c176-8f4d475c2398"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 88582 unique tokens.\n","Shape of data tensor: (25000, 100)\n","Shape of label tensor: (25000,)\n"]}]},{"cell_type":"markdown","source":["------------------------------\n","- Using GLoVe for Embedding Layer\n","Download and Extract GLoVe"],"metadata":{"id":"c65-GKRsZRz8"}},{"cell_type":"code","source":["!wget https://nlp.stanford.edu/data/glove.6B.zip #download the data file\n","\n","!unzip glove.6B.zip # extract the file"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y88K-sf45KP2","executionInfo":{"status":"ok","timestamp":1675641145678,"user_tz":-210,"elapsed":37172,"user":{"displayName":"Mo A","userId":"00449421205978629245"}},"outputId":"f4428c24-ace8-46aa-a5f8-ef9dd4fbe5ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  glove.6B.zip.1\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","#glove_dir = 'glove.6B'\n","embeddings_index = {}\n","f = open(os.path.join('', 'glove.6B.100d.txt'))\n","for line in f:\n","  values = line.split()\n","  word = values[0]\n","  coefs = np.asarray(values[1:], dtype='float32')\n","  embeddings_index[word] = coefs\n","f.close()"],"metadata":{"id":"ZPP0guuU6GfR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["-----------------------------------\n","- Specialize embedding vectors in GLoVe to our IMDB data"],"metadata":{"id":"0yw23pYRM76Q"}},{"cell_type":"code","source":["max_words = 10000\n","embedding_dim = 100\n","embedding_matrix = np.zeros((max_words, embedding_dim))\n","\n","for word, i in word_index.items():\n","  if(i < max_words):\n","    embedding_vector = embeddings_index.get(word)\n","    if(embedding_vector is not None):\n","      embedding_matrix[i] = embedding_vector"],"metadata":{"id":"11aooiO5IV02"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Embedding, Flatten, Dense\n","\n","model = Sequential()\n","model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n","model.add(Flatten())\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.summary ()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tcl4Az75NTmy","executionInfo":{"status":"ok","timestamp":1675611306019,"user_tz":-210,"elapsed":1131,"user":{"displayName":"Mo A","userId":"00449421205978629245"}},"outputId":"a1e9e0ae-0c56-4cd9-9ef6-a534d7c606ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 100, 100)          1000000   \n","                                                                 \n"," flatten (Flatten)           (None, 10000)             0         \n","                                                                 \n"," dense (Dense)               (None, 32)                320032    \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 1,320,065\n","Trainable params: 1,320,065\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.layers[0].set_weights( [embedding_matrix] )\n","model.layers[0].trainable = False"],"metadata":{"id":"04B0TgGaN3As"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n","\n","history = model.fit(x_train, y_train,\n","epochs=10,\n","batch_size=32,\n","validation_data=(X_val, y_val))\n","\n","model.save_weights('pre_trained_glove_model.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ami8_8POmuH","executionInfo":{"status":"ok","timestamp":1675611791993,"user_tz":-210,"elapsed":12671,"user":{"displayName":"Mo A","userId":"00449421205978629245"}},"outputId":"d129d65a-babf-484d-d8e2-c2e077bf0e2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","7/7 [==============================] - 3s 247ms/step - loss: 1.2500 - acc: 0.4850 - val_loss: 0.6929 - val_acc: 0.5114\n","Epoch 2/10\n","7/7 [==============================] - 1s 111ms/step - loss: 0.6501 - acc: 0.6800 - val_loss: 0.6915 - val_acc: 0.5297\n","Epoch 3/10\n","7/7 [==============================] - 1s 113ms/step - loss: 0.6138 - acc: 0.6200 - val_loss: 0.8936 - val_acc: 0.5028\n","Epoch 4/10\n","7/7 [==============================] - 1s 112ms/step - loss: 0.6006 - acc: 0.7050 - val_loss: 0.6958 - val_acc: 0.5473\n","Epoch 5/10\n","7/7 [==============================] - 1s 221ms/step - loss: 0.4171 - acc: 0.7650 - val_loss: 0.7091 - val_acc: 0.5522\n","Epoch 6/10\n","7/7 [==============================] - 1s 109ms/step - loss: 0.2622 - acc: 0.9000 - val_loss: 1.3104 - val_acc: 0.5028\n","Epoch 7/10\n","7/7 [==============================] - 1s 113ms/step - loss: 0.1794 - acc: 0.9550 - val_loss: 0.8739 - val_acc: 0.5155\n","Epoch 8/10\n","7/7 [==============================] - 1s 108ms/step - loss: 0.2045 - acc: 0.9450 - val_loss: 0.8046 - val_acc: 0.5512\n","Epoch 9/10\n","7/7 [==============================] - 1s 220ms/step - loss: 0.0690 - acc: 1.0000 - val_loss: 0.9021 - val_acc: 0.5365\n","Epoch 10/10\n","7/7 [==============================] - 1s 111ms/step - loss: 0.0464 - acc: 1.0000 - val_loss: 0.7431 - val_acc: 0.5642\n"]}]},{"cell_type":"markdown","source":["- Evaluation\ton\tthe\ttest\tdata"],"metadata":{"id":"mNSg42ZdQSzG"}},{"cell_type":"code","source":["test_dir = os.path.join('aclImdb/', 'test')\n","labels = []\n","texts = []\n","for label_type in ['neg', 'pos']:\n","  dir_name = os.path.join(test_dir, label_type)\n","  for fname in sorted(os.listdir(dir_name)):\n","    if(fname[-4:] == '.txt'):\n","      f = open(os.path.join(dir_name, fname) )\n","      texts .append(f.read())\n","      f.close()\n","      if label_type == 'neg':\n","        labels.append(0)\n","      else:\n","        labels.append(1)\n","\n","sequences = tokenizer.texts_to_sequences(texts)\n","x_test = pad_sequences(sequences, maxlen=maxlen)\n","y_test = np.asarray(labels)\n","model.load_weights('pre_trained_glove_model.h5')\n","model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ChEMAX-wPq0i","executionInfo":{"status":"ok","timestamp":1675612220028,"user_tz":-210,"elapsed":16648,"user":{"displayName":"Mo A","userId":"00449421205978629245"}},"outputId":"057a3091-9c39-4139-960c-95bad16b4d12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["782/782 [==============================] - 2s 2ms/step - loss: 0.7367 - acc: 0.5697\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.7366601824760437, 0.5697199702262878]"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["------------------------------------\n","- Numpy implementation\tof\ta\tsimple\tRNN\n"],"metadata":{"id":"yYm9Tb9LtLK9"}},{"cell_type":"code","source":["import numpy as np\n","timesteps = 100\n","input_features = 32\n","\n","output_features = 64\n","\n","inputs = np.random.random((timesteps, input_features))\n","state_t = np.zeros((output_features,))\n","\n","W = np.random.random((output_features, input_features))\n","U = np.random.random((output_features, output_features))\n","b = np.random.random((output_features, ))\n","\n","successive_outputs = []\n","\n","for input_t in inputs:\n","  output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n","  successive_outputs.append(output_t)\n","  state_t = output_t\n","\n","final_output_sequence = np.array(successive_outputs)"],"metadata":{"id":"O0JA492dRSWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Flatten, Dense, Embedding, SimpleRNN\n","\n","max_features = 10000\n","maxlen = 500\n","model = Sequential()\n","\n","model.add(Embedding(max_features, 100))\n","model.add(SimpleRNN(100))\n","model.add(Dense(1, activation='sigmoid') )\n","\n","model.layers[0].set_weights( [embedding_matrix] )\n","model.layers[0].trainable = False\n","model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n","\n","history = model.fit(x_train, y_train,\n","epochs=10,\n","batch_size=128,\n","validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jqmq1strvEEb","executionInfo":{"status":"ok","timestamp":1675641624348,"user_tz":-210,"elapsed":5594,"user":{"displayName":"Mo A","userId":"00449421205978629245"}},"outputId":"67b8c8fb-14fb-4fc1-fdde-e5884fd442c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","2/2 [==============================] - 3s 323ms/step - loss: 0.7849 - acc: 0.5000 - val_loss: 0.6663 - val_acc: 0.5500\n","Epoch 2/15\n","2/2 [==============================] - 0s 73ms/step - loss: 0.6161 - acc: 0.6625 - val_loss: 0.6273 - val_acc: 0.5750\n","Epoch 3/15\n","2/2 [==============================] - 0s 65ms/step - loss: 0.5633 - acc: 0.7563 - val_loss: 0.6413 - val_acc: 0.6500\n","Epoch 4/15\n","2/2 [==============================] - 0s 73ms/step - loss: 0.5138 - acc: 0.8062 - val_loss: 0.6460 - val_acc: 0.6500\n","Epoch 5/15\n","2/2 [==============================] - 0s 66ms/step - loss: 0.4756 - acc: 0.8438 - val_loss: 0.6310 - val_acc: 0.5750\n","Epoch 6/15\n","2/2 [==============================] - 0s 67ms/step - loss: 0.4431 - acc: 0.8438 - val_loss: 0.7149 - val_acc: 0.5750\n","Epoch 7/15\n","2/2 [==============================] - 0s 63ms/step - loss: 0.4233 - acc: 0.8500 - val_loss: 0.6561 - val_acc: 0.6750\n","Epoch 8/15\n","2/2 [==============================] - 0s 63ms/step - loss: 0.3685 - acc: 0.9187 - val_loss: 0.6339 - val_acc: 0.5500\n","Epoch 9/15\n","2/2 [==============================] - 0s 64ms/step - loss: 0.3512 - acc: 0.8750 - val_loss: 0.6639 - val_acc: 0.6500\n","Epoch 10/15\n","2/2 [==============================] - 0s 59ms/step - loss: 0.3020 - acc: 0.9375 - val_loss: 0.6781 - val_acc: 0.6250\n","Epoch 11/15\n","2/2 [==============================] - 0s 65ms/step - loss: 0.2672 - acc: 0.9563 - val_loss: 0.6582 - val_acc: 0.6250\n","Epoch 12/15\n","2/2 [==============================] - 0s 64ms/step - loss: 0.2402 - acc: 0.9563 - val_loss: 0.7232 - val_acc: 0.6000\n","Epoch 13/15\n","2/2 [==============================] - 0s 63ms/step - loss: 0.2090 - acc: 0.9875 - val_loss: 0.7435 - val_acc: 0.5750\n","Epoch 14/15\n","2/2 [==============================] - 0s 67ms/step - loss: 0.1797 - acc: 0.9937 - val_loss: 0.7534 - val_acc: 0.5750\n","Epoch 15/15\n","2/2 [==============================] - 0s 94ms/step - loss: 0.1494 - acc: 0.9937 - val_loss: 0.7310 - val_acc: 0.5500\n"]}]},{"cell_type":"markdown","source":["-----------------------\n","- LSTM"],"metadata":{"id":"572Qdk2tFMz9"}},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Flatten, Dense, Embedding, LSTM\n","\n","max_features = 10000\n","maxlen = 500\n","model = Sequential()\n","\n","model.add(Embedding(max_features, 32))\n","model.add(LSTM(32))\n","model.add(Dense(1, activation='sigmoid') )\n","\n","#model.layers[0].set_weights( [embedding_matrix] )\n","#model.layers[0].trainable = False\n","model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n","\n","history = model.fit(x_train, y_train,\n","epochs=15,\n","batch_size=128,\n","validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LiMMA8B6ARwn","executionInfo":{"status":"ok","timestamp":1675642449437,"user_tz":-210,"elapsed":7536,"user":{"displayName":"Mo A","userId":"00449421205978629245"}},"outputId":"4f054d36-e9c0-4351-e178-1780f4b24783"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","2/2 [==============================] - 3s 590ms/step - loss: 0.6938 - acc: 0.4750 - val_loss: 0.6917 - val_acc: 0.6000\n","Epoch 2/15\n","2/2 [==============================] - 0s 90ms/step - loss: 0.6883 - acc: 0.7312 - val_loss: 0.6899 - val_acc: 0.5250\n","Epoch 3/15\n","2/2 [==============================] - 0s 97ms/step - loss: 0.6827 - acc: 0.7688 - val_loss: 0.6876 - val_acc: 0.5250\n","Epoch 4/15\n","2/2 [==============================] - 0s 75ms/step - loss: 0.6749 - acc: 0.7812 - val_loss: 0.6847 - val_acc: 0.6250\n","Epoch 5/15\n","2/2 [==============================] - 0s 70ms/step - loss: 0.6624 - acc: 0.8813 - val_loss: 0.6778 - val_acc: 0.6000\n","Epoch 6/15\n","2/2 [==============================] - 0s 75ms/step - loss: 0.6379 - acc: 0.8813 - val_loss: 0.6556 - val_acc: 0.5500\n","Epoch 7/15\n","2/2 [==============================] - 0s 75ms/step - loss: 0.5479 - acc: 0.5938 - val_loss: 0.6681 - val_acc: 0.6250\n","Epoch 8/15\n","2/2 [==============================] - 0s 74ms/step - loss: 0.5696 - acc: 0.9750 - val_loss: 0.6158 - val_acc: 0.6750\n","Epoch 9/15\n","2/2 [==============================] - 0s 75ms/step - loss: 0.5155 - acc: 0.9125 - val_loss: 0.6572 - val_acc: 0.7000\n","Epoch 10/15\n","2/2 [==============================] - 0s 75ms/step - loss: 0.4994 - acc: 0.9812 - val_loss: 0.6191 - val_acc: 0.7000\n","Epoch 11/15\n","2/2 [==============================] - 0s 74ms/step - loss: 0.3851 - acc: 0.9937 - val_loss: 0.6177 - val_acc: 0.7250\n","Epoch 12/15\n","2/2 [==============================] - 0s 73ms/step - loss: 0.3234 - acc: 0.9812 - val_loss: 0.6013 - val_acc: 0.7250\n","Epoch 13/15\n","2/2 [==============================] - 0s 78ms/step - loss: 0.3023 - acc: 1.0000 - val_loss: 0.7051 - val_acc: 0.7000\n","Epoch 14/15\n","2/2 [==============================] - 0s 72ms/step - loss: 0.2746 - acc: 0.9937 - val_loss: 0.6619 - val_acc: 0.7250\n","Epoch 15/15\n","2/2 [==============================] - 0s 83ms/step - loss: 0.2560 - acc: 1.0000 - val_loss: 0.6655 - val_acc: 0.7250\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"WyTHTr9gXKjM"},"execution_count":null,"outputs":[]}]}